Run training...
Experiment dir : /m/triton/scratch/elec/puhe/p/jaina5/transformer-xl/FinnishXL/-Ktrain/20190903-133137
Loading cached dataset...
====================================================================================================
    - data : /m/triton/scratch/elec/puhe/p/jaina5/transformer-xl/FinnishXL/data/cp_kiel_train/
    - dataset : Ktrain
    - n_layer : 96
    - n_head : 8
    - d_head : 40
    - d_embed : 256
    - d_model : 256
    - d_inner : 1024
    - dropout : 0.05
    - dropatt : 0.05
    - init : normal
    - emb_init : normal
    - init_range : 0.1
    - emb_init_range : 0.01
    - init_std : 0.02
    - proj_init_std : 0.01
    - optim : adam
    - lr : 0.00025
    - mom : 0.0
    - scheduler : cosine
    - warmup_step : 40000
    - decay_rate : 0.5
    - lr_min : 0.0
    - clip : 0.25
    - clip_nonemb : False
    - max_step : 200000
    - batch_size : 88
    - batch_chunk : 4
    - tgt_len : 150
    - eval_tgt_len : 150
    - ext_len : 0
    - mem_len : 150
    - not_tied : False
    - seed : 1111
    - cuda : True
    - adaptive : False
    - div_val : 1
    - pre_lnorm : False
    - varlen : False
    - multi_gpu : False
    - log_interval : 200
    - eval_interval : 4000
    - work_dir : /m/triton/scratch/elec/puhe/p/jaina5/transformer-xl/FinnishXL/-Ktrain/20190903-133137
    - restart : True
    - restart_dir : /m/triton/scratch/elec/puhe/p/jaina5/transformer-xl/FinnishXL/-Ktrain/20190828-133850
    - debug : False
    - same_length : False
    - attn_type : 0
    - clamp_len : -1
    - eta_min : 0.0
    - gpu0_bsz : -1
    - max_eval_steps : -1
    - sample_softmax : -1
    - patience : 0
    - finetune_v2 : False
    - finetune_v3 : False
    - fp16 : False
    - static_loss_scale : 1
    - dynamic_loss_scale : False
    - tied : True
    - n_token : 34519
    - n_all_param : 98746455
    - n_nonemb_param : 89874432
====================================================================================================
#params = 98746455
#non emb params = 89874432
Traceback (most recent call last):
  File "train_kiel_train.py", line 539, in <module>
    train()
  File "train_kiel_train.py", line 442, in train
    loss.backward()
  File "/share/apps2/anaconda/anaconda3/latest/lib/python3.6/site-packages/torch/tensor.py", line 102, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/share/apps2/anaconda/anaconda3/latest/lib/python3.6/site-packages/torch/autograd/__init__.py", line 90, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 434.62 MiB (GPU 0; 31.72 GiB total capacity; 27.18 GiB already allocated; 79.56 MiB free; 1.58 GiB cached)
srun: error: gpu33: task 0: Exited with exit code 1
srun: Terminating job step 44877173.0
